{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c03e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, chi2, mutual_info_classif\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy as sp\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5acc6c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have used lemmatization and removed stop words if any\n",
    "\n",
    "def text_process(text):\n",
    "    lemmatiser = WordNetLemmatizer() \n",
    "    not_punct = [char for char in text if char not in string.punctuation]\n",
    "    not_punct = ''.join(not_punct)\n",
    "    a = ''\n",
    "    i = 0\n",
    "    for i in range(len(not_punct.split())):\n",
    "        b = lemmatiser.lemmatize(not_punct.split()[i], pos=\"v\")\n",
    "        a = a + b + ' '\n",
    "\n",
    "    not_stopwords = \"\"\n",
    "    for word in a.split():\n",
    "        if word.lower():\n",
    "            not_stopwords = not_stopwords + word + \" \"\n",
    "    \n",
    "    return not_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c6e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have processed the text, where we have dropped rows having NaN values and used text_process function\n",
    "\n",
    "df = pd.read_csv(\"./Enron_29_Features.csv\").drop([\"Unnamed: 0\"], axis=1)\n",
    "df = df[df[\"Email Length\"].notna()]\n",
    "df = df[df[\"Author\"].notna()]\n",
    "cleaned_text = df[\"Text\"].apply(lambda row: text_process(row))\n",
    "df[\"Processed Text\"] = cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f461242a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have used LabelEncoder() to encode the class names\n",
    "\n",
    "y = df[\"Folder\"]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "#Dropped all unrequired columns/attributes\n",
    "\n",
    "X = df.drop([\"Author\", \"File\", \"Raw Text\", \"Message ID\", \"Folder\", \"Text\"], axis=1)\n",
    "\n",
    "#Dropped rows having NaN values\n",
    "\n",
    "X = X[X[\"Email Length\"] != 0]\n",
    "X = X[X[\"Average Word Length\"].notna()]\n",
    "X = X[X[\"Most Common Word\"].notna()]\n",
    "X = X.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88cc972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are checking if still any NaN values are present, dropping if present and printing the shape after the change\n",
    "\n",
    "for column in X.columns:\n",
    "    if X[column].dropna().shape[0] != X.shape[0]:\n",
    "        print(column)\n",
    "        print(X[column].dropna().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9978d67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Training Accuracy\n",
      "0.9904156915190014\n",
      "Testing Accuracy\n",
      "0.819047619047619\n",
      "Round 2\n",
      "Training Accuracy\n",
      "0.9903605059341394\n",
      "Testing Accuracy\n",
      "0.8094282848545636\n",
      "Round 3\n",
      "Training Accuracy\n",
      "0.9904719451718951\n",
      "Testing Accuracy\n",
      "0.8104312938816449\n",
      "Round 4\n",
      "Training Accuracy\n",
      "0.9909177021229175\n",
      "Testing Accuracy\n",
      "0.8234704112337011\n",
      "Round 5\n",
      "Training Accuracy\n",
      "0.9900261882208725\n",
      "Testing Accuracy\n",
      "0.8144433299899699\n",
      "Round 6\n",
      "Training Accuracy\n",
      "0.9899704686019948\n",
      "Testing Accuracy\n",
      "0.8074222668004012\n",
      "Round 7\n",
      "Training Accuracy\n",
      "0.9901376274586282\n",
      "Testing Accuracy\n",
      "0.8044132397191575\n",
      "Round 8\n",
      "Training Accuracy\n",
      "0.9907505432662841\n",
      "Testing Accuracy\n",
      "0.8149448345035105\n",
      "Round 9\n",
      "Training Accuracy\n",
      "0.9898033097453613\n",
      "Testing Accuracy\n",
      "0.8224674022066198\n",
      "Round 10\n",
      "Training Accuracy\n",
      "0.9895804312698501\n",
      "Testing Accuracy\n",
      "0.8094282848545636\n",
      "===========================\n",
      "Average Training Accuracy:\n",
      "0.9902434413310944\n",
      "Average Testing Accuracy:\n",
      "0.8135496967091752\n",
      "F1 Score:\n",
      "0.8094282848545635\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Model -\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train = X.loc[train_index]\n",
    "    X_test = X.loc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    ct_one = ColumnTransformer([(\"minmax\", MinMaxScaler(), [\"Email Length\", \"Digit Density\", \"Space Density\", \"Number of Paragraphs\", \"Average Sentences per Paragraph\", \"Average Word Length\", \"Average Sentence Length\", \"Polarity\", \"Subjectivity\", \"Short Word Ratio\", \"Punc Frequency\", \"Number Words\", \"Freq Most Common Word\", \"Total Special Character Count\", \"Count of Max Special Char\"])])\n",
    "    ct_two = ColumnTransformer([((\"tfidfvectorizer\", CountVectorizer(), \"Processed Text\"))])\n",
    "    ct_three = ColumnTransformer([(\"ohe\", OneHotEncoder(handle_unknown = \"ignore\"), [\"Farewell Words\", \"Last Punc\", \"Punc after Greeting\", \"Greeting\", \"Most Common Word\", \"Freq Punc\", \"Most Common POS\", \"Single Sentence\", \"Greeting\", \"Most Common Word\", \"Max Occurring Special Char\"])])\n",
    "    \n",
    "    ct_three.fit(X_train)\n",
    "    X_train_transform_three = ct_three.transform(X_train)\n",
    "    X_test_transform_three = ct_three.transform(X_test)\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=1000)\n",
    "    X_train_transform_three_new = fs.fit_transform(X_train_transform_three, y_train)\n",
    "    X_test_transform_three_new = fs.transform(X_test_transform_three)\n",
    "\n",
    "    \n",
    "    ct_two.fit(X_train)\n",
    "    X_train_transform_two = ct_two.transform(X_train)\n",
    "    X_test_transform_two = ct_two.transform(X_test)\n",
    "    fs = SelectKBest(k=6000)\n",
    "    X_train_transform_two_new = fs.fit_transform(X_train_transform_two, y_train)\n",
    "    X_test_transform_two_new = fs.transform(X_test_transform_two)\n",
    "    \n",
    "    ct_one.fit(X_train)\n",
    "    X_train_transform_one = ct_one.transform(X_train)\n",
    "    X_test_transform_one = ct_one.transform(X_test)\n",
    "    \n",
    "    X_train_transform = sp.sparse.hstack((X_train_transform_one, X_train_transform_two_new, X_train_transform_three_new))\n",
    "    X_test_transform = sp.sparse.hstack((X_test_transform_one, X_test_transform_two_new, X_test_transform_three_new))\n",
    "    \n",
    "    fit_model = model.fit(X_train_transform, y_train)\n",
    "    train_acc = model.score(X_train_transform, y_train)\n",
    "    test_acc = model.score(X_test_transform, y_test)\n",
    "    \n",
    "    print(\"Round {}\".format(i))\n",
    "    print(\"Training Accuracy\")\n",
    "    print(train_acc)\n",
    "    print(\"Testing Accuracy\")\n",
    "    print(test_acc)\n",
    "    \n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "\n",
    "Y_pred = fit_model.predict(X_test_transform)\n",
    "f1_dt = f1_score(y_test, Y_pred, average = \"micro\")\n",
    "avg_train_acc_dt = sum(train_accuracies)/len(train_accuracies)\n",
    "avg_test_acc_dt = sum(test_accuracies)/len(test_accuracies)\n",
    "print(\"===========================\")\n",
    "print(\"Average Training Accuracy:\")\n",
    "print(avg_train_acc_dt)\n",
    "print(\"Average Testing Accuracy:\")\n",
    "print(avg_test_acc_dt)\n",
    "print(\"F1 Score:\")\n",
    "print(f1_dt)\n",
    "print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5d1e521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Training Accuracy\n",
      "0.8414688509974367\n",
      "Testing Accuracy\n",
      "0.8285714285714286\n",
      "Round 2\n",
      "Training Accuracy\n",
      "0.8387474229676269\n",
      "Testing Accuracy\n",
      "0.831494483450351\n",
      "Round 3\n",
      "Training Accuracy\n",
      "0.8399732545829387\n",
      "Testing Accuracy\n",
      "0.8284854563691073\n",
      "Round 4\n",
      "Training Accuracy\n",
      "0.8411433665793726\n",
      "Testing Accuracy\n",
      "0.8174523570712137\n",
      "Round 5\n",
      "Training Accuracy\n",
      "0.8390817406808937\n",
      "Testing Accuracy\n",
      "0.820962888665998\n",
      "Round 6\n",
      "Training Accuracy\n",
      "0.8383573856354822\n",
      "Testing Accuracy\n",
      "0.8294884653961886\n",
      "Round 7\n",
      "Training Accuracy\n",
      "0.8379673483033376\n",
      "Testing Accuracy\n",
      "0.8034102306920762\n",
      "Round 8\n",
      "Training Accuracy\n",
      "0.8393603387752828\n",
      "Testing Accuracy\n",
      "0.8104312938816449\n",
      "Round 9\n",
      "Training Accuracy\n",
      "0.8423691981946844\n",
      "Testing Accuracy\n",
      "0.8370110330992979\n",
      "Round 10\n",
      "Training Accuracy\n",
      "0.8404190115339611\n",
      "Testing Accuracy\n",
      "0.820962888665998\n",
      "===========================\n",
      "Average Training Accuracy:\n",
      "0.8398887918251017\n",
      "Average Testing Accuracy:\n",
      "0.8228270525863305\n",
      "F1 Score:\n",
      "0.820962888665998\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes Model -\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model = MultinomialNB()\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train = X.loc[train_index]\n",
    "    X_test = X.loc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    ct_one = ColumnTransformer([(\"minmax\", MinMaxScaler(), [\"Email Length\", \"Digit Density\", \"Space Density\", \"Number of Paragraphs\", \"Average Sentences per Paragraph\", \"Average Word Length\", \"Average Sentence Length\", \"Polarity\", \"Subjectivity\", \"Short Word Ratio\", \"Punc Frequency\", \"Number Words\", \"Freq Most Common Word\", \"Total Special Character Count\", \"Count of Max Special Char\"])])\n",
    "    ct_two = ColumnTransformer([((\"tfidfvectorizer\", CountVectorizer(), \"Processed Text\"))])\n",
    "    ct_three = ColumnTransformer([(\"ohe\", OneHotEncoder(handle_unknown = \"ignore\"), [\"Farewell Words\", \"Last Punc\", \"Punc after Greeting\", \"Greeting\", \"Most Common Word\", \"Freq Punc\", \"Most Common POS\", \"Single Sentence\", \"Greeting\", \"Most Common Word\", \"Max Occurring Special Char\"])])\n",
    "    \n",
    "    ct_three.fit(X_train)\n",
    "    X_train_transform_three = ct_three.transform(X_train)\n",
    "    X_test_transform_three = ct_three.transform(X_test)\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=1000)\n",
    "    X_train_transform_three_new = fs.fit_transform(X_train_transform_three, y_train)\n",
    "    X_test_transform_three_new = fs.transform(X_test_transform_three)\n",
    "\n",
    "    \n",
    "    ct_two.fit(X_train)\n",
    "    X_train_transform_two = ct_two.transform(X_train)\n",
    "    X_test_transform_two = ct_two.transform(X_test)\n",
    "    fs = SelectKBest(k=6000)\n",
    "    X_train_transform_two_new = fs.fit_transform(X_train_transform_two, y_train)\n",
    "    X_test_transform_two_new = fs.transform(X_test_transform_two)\n",
    "    \n",
    "    ct_one.fit(X_train)\n",
    "    X_train_transform_one = ct_one.transform(X_train)\n",
    "    X_test_transform_one = ct_one.transform(X_test)\n",
    "\n",
    "    X_train_transform = sp.sparse.hstack((X_train_transform_one, X_train_transform_two_new, X_train_transform_three_new))\n",
    "    X_test_transform = sp.sparse.hstack((X_test_transform_one, X_test_transform_two_new, X_test_transform_three_new))\n",
    "    \n",
    "    fit_model = model.fit(X_train_transform, y_train)\n",
    "    train_acc = model.score(X_train_transform, y_train)\n",
    "    test_acc = model.score(X_test_transform, y_test)\n",
    "    \n",
    "    print(\"Round {}\".format(i))\n",
    "    print(\"Training Accuracy\")\n",
    "    print(train_acc)\n",
    "    print(\"Testing Accuracy\")\n",
    "    print(test_acc)\n",
    "    \n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "\n",
    "Y_pred = fit_model.predict(X_test_transform)\n",
    "f1_mnb = f1_score(y_test, Y_pred, average = \"micro\")\n",
    "avg_train_acc_mnb = sum(train_accuracies)/len(train_accuracies)\n",
    "avg_test_acc_mnb = sum(test_accuracies)/len(test_accuracies)\n",
    "print(\"===========================\")\n",
    "print(\"Average Training Accuracy:\")\n",
    "print(avg_train_acc_mnb)\n",
    "print(\"Average Testing Accuracy:\")\n",
    "print(avg_test_acc_mnb)\n",
    "print(\"F1 Score:\")\n",
    "print(f1_mnb)\n",
    "print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99e9c5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Training Accuracy\n",
      "0.9904156915190014\n",
      "Testing Accuracy\n",
      "0.8791979949874686\n",
      "Round 2\n",
      "Training Accuracy\n",
      "0.9903605059341394\n",
      "Testing Accuracy\n",
      "0.8771313941825476\n",
      "Round 3\n",
      "Training Accuracy\n",
      "0.9904719451718951\n",
      "Testing Accuracy\n",
      "0.8716148445336008\n",
      "Round 4\n",
      "Training Accuracy\n",
      "0.9909177021229175\n",
      "Testing Accuracy\n",
      "0.870110330992979\n",
      "Round 5\n",
      "Training Accuracy\n",
      "0.9900261882208725\n",
      "Testing Accuracy\n",
      "0.8756268806419257\n",
      "Round 6\n",
      "Training Accuracy\n",
      "0.9899704686019948\n",
      "Testing Accuracy\n",
      "0.8645937813440321\n",
      "Round 7\n",
      "Training Accuracy\n",
      "0.9901376274586282\n",
      "Testing Accuracy\n",
      "0.8671013039117352\n",
      "Round 8\n",
      "Training Accuracy\n",
      "0.9907505432662841\n",
      "Testing Accuracy\n",
      "0.8721163490471414\n",
      "Round 9\n",
      "Training Accuracy\n",
      "0.9898033097453613\n",
      "Testing Accuracy\n",
      "0.8751253761283851\n",
      "Round 10\n",
      "Training Accuracy\n",
      "0.9895804312698501\n",
      "Testing Accuracy\n",
      "0.8681043129388164\n",
      "===========================\n",
      "Average Training Accuracy:\n",
      "0.9902434413310944\n",
      "Average Testing Accuracy:\n",
      "0.8720722568708632\n",
      "F1 Score:\n",
      "0.8681043129388164\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "#Random Forest Classifier Model -\n",
    "# Average Training Accuracy:\n",
    "# 0.9902434413310944\n",
    "# Average Testing Accuracy:\n",
    "# 0.8715713053948815\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model = RandomForestClassifier(random_state=3)\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train = X.loc[train_index]\n",
    "    X_test = X.loc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    ct_one = ColumnTransformer([(\"minmax\", MinMaxScaler(), [\"Email Length\", \"Digit Density\", \"Space Density\", \"Number of Paragraphs\", \"Average Sentences per Paragraph\", \"Average Word Length\", \"Average Sentence Length\", \"Polarity\", \"Subjectivity\", \"Short Word Ratio\", \"Punc Frequency\", \"Number Words\", \"Freq Most Common Word\", \"Total Special Character Count\", \"Count of Max Special Char\"])])\n",
    "    ct_two = ColumnTransformer([((\"tfidfvectorizer\", CountVectorizer(), \"Processed Text\"))])\n",
    "    ct_three = ColumnTransformer([(\"ohe\", OneHotEncoder(handle_unknown = \"ignore\"), [\"Farewell Words\", \"Last Punc\", \"Punc after Greeting\", \"Greeting\", \"Most Common Word\", \"Freq Punc\", \"Most Common POS\", \"Single Sentence\", \"Greeting\", \"Most Common Word\", \"Max Occurring Special Char\"])])\n",
    "    \n",
    "    ct_three.fit(X_train)\n",
    "    X_train_transform_three = ct_three.transform(X_train)\n",
    "    X_test_transform_three = ct_three.transform(X_test)\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=1000)\n",
    "    X_train_transform_three_new = fs.fit_transform(X_train_transform_three, y_train)\n",
    "    X_test_transform_three_new = fs.transform(X_test_transform_three)\n",
    "\n",
    "    \n",
    "    ct_two.fit(X_train)\n",
    "    X_train_transform_two = ct_two.transform(X_train)\n",
    "    X_test_transform_two = ct_two.transform(X_test)\n",
    "    fs = SelectKBest(k=6000)\n",
    "    X_train_transform_two_new = fs.fit_transform(X_train_transform_two, y_train)\n",
    "    X_test_transform_two_new = fs.transform(X_test_transform_two)\n",
    "    \n",
    "    ct_one.fit(X_train)\n",
    "    X_train_transform_one = ct_one.transform(X_train)\n",
    "    X_test_transform_one = ct_one.transform(X_test)\n",
    "\n",
    "    X_train_transform = sp.sparse.hstack((X_train_transform_one, X_train_transform_two_new, X_train_transform_three_new))\n",
    "    X_test_transform = sp.sparse.hstack((X_test_transform_one, X_test_transform_two_new, X_test_transform_three_new))\n",
    "    \n",
    "    fit_model = model.fit(X_train_transform, y_train)\n",
    "    train_acc = model.score(X_train_transform, y_train)\n",
    "    test_acc = model.score(X_test_transform, y_test)\n",
    "    \n",
    "    print(\"Round {}\".format(i))\n",
    "    print(\"Training Accuracy\")\n",
    "    print(train_acc)\n",
    "    print(\"Testing Accuracy\")\n",
    "    print(test_acc)\n",
    "    \n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "Y_pred = fit_model.predict(X_test_transform)\n",
    "f1_rf = f1_score(y_test, Y_pred, average = \"micro\")    \n",
    "avg_train_acc_rf = sum(train_accuracies)/len(train_accuracies)\n",
    "avg_test_acc_rf = sum(test_accuracies)/len(test_accuracies)\n",
    "print(\"===========================\")\n",
    "print(\"Average Training Accuracy:\")\n",
    "print(avg_train_acc_rf)\n",
    "print(\"Average Testing Accuracy:\")\n",
    "print(avg_test_acc_rf)\n",
    "print(\"F1 Score:\")\n",
    "print(f1_rf)\n",
    "print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c1fcd3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "Training Accuracy\n",
      "0.9626100523793603\n",
      "Testing Accuracy\n",
      "0.8611528822055138\n",
      "Round 2\n",
      "Training Accuracy\n",
      "0.9614420237365576\n",
      "Testing Accuracy\n",
      "0.8796389167502507\n",
      "Round 3\n",
      "Training Accuracy\n",
      "0.9626121357329915\n",
      "Testing Accuracy\n",
      "0.8570712136409228\n",
      "Round 4\n",
      "Training Accuracy\n",
      "0.9621106591630914\n",
      "Testing Accuracy\n",
      "0.854062186559679\n",
      "Round 5\n",
      "Training Accuracy\n",
      "0.9614420237365576\n",
      "Testing Accuracy\n",
      "0.8681043129388164\n",
      "Round 6\n",
      "Training Accuracy\n",
      "0.9609962667855352\n",
      "Testing Accuracy\n",
      "0.8585757271815446\n",
      "Round 7\n",
      "Training Accuracy\n",
      "0.9608848275477796\n",
      "Testing Accuracy\n",
      "0.8520561685055166\n",
      "Round 8\n",
      "Training Accuracy\n",
      "0.9630021730651362\n",
      "Testing Accuracy\n",
      "0.8485456369107321\n",
      "Round 9\n",
      "Training Accuracy\n",
      "0.9611077060232908\n",
      "Testing Accuracy\n",
      "0.8741223671013039\n",
      "Round 10\n",
      "Training Accuracy\n",
      "0.9614977433554355\n",
      "Testing Accuracy\n",
      "0.8610832497492478\n",
      "===========================\n",
      "Average Training Accuracy:\n",
      "0.9617705611525735\n",
      "Average Testing Accuracy:\n",
      "0.8614412661543526\n",
      "F1 Score:\n",
      "0.8610832497492478\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Classification Model -\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "model = svm.SVC(kernel = 'linear')\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in kfold.split(X):\n",
    "    X_train = X.loc[train_index]\n",
    "    X_test = X.loc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    ct_one = ColumnTransformer([(\"minmax\", MinMaxScaler(), [\"Email Length\", \"Digit Density\", \"Space Density\", \"Number of Paragraphs\", \"Average Sentences per Paragraph\", \"Average Word Length\", \"Average Sentence Length\", \"Polarity\", \"Subjectivity\", \"Short Word Ratio\", \"Punc Frequency\", \"Number Words\", \"Freq Most Common Word\", \"Total Special Character Count\", \"Count of Max Special Char\"])])\n",
    "    ct_two = ColumnTransformer([((\"tfidfvectorizer\", CountVectorizer(), \"Processed Text\"))])\n",
    "    ct_three = ColumnTransformer([(\"ohe\", OneHotEncoder(handle_unknown = \"ignore\"), [\"Farewell Words\", \"Last Punc\", \"Punc after Greeting\", \"Greeting\", \"Most Common Word\", \"Freq Punc\", \"Most Common POS\", \"Single Sentence\", \"Greeting\", \"Most Common Word\", \"Max Occurring Special Char\"])])\n",
    "    \n",
    "    ct_three.fit(X_train)\n",
    "    X_train_transform_three = ct_three.transform(X_train)\n",
    "    X_test_transform_three = ct_three.transform(X_test)\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=1000)\n",
    "    X_train_transform_three_new = fs.fit_transform(X_train_transform_three, y_train)\n",
    "    X_test_transform_three_new = fs.transform(X_test_transform_three)\n",
    "\n",
    "    \n",
    "    ct_two.fit(X_train)\n",
    "    X_train_transform_two = ct_two.transform(X_train)\n",
    "    X_test_transform_two = ct_two.transform(X_test)\n",
    "    fs = SelectKBest(k=6000)\n",
    "    X_train_transform_two_new = fs.fit_transform(X_train_transform_two, y_train)\n",
    "    X_test_transform_two_new = fs.transform(X_test_transform_two)\n",
    "    \n",
    "    ct_one.fit(X_train)\n",
    "    X_train_transform_one = ct_one.transform(X_train)\n",
    "    X_test_transform_one = ct_one.transform(X_test)\n",
    "\n",
    "    X_train_transform = sp.sparse.hstack((X_train_transform_one, X_train_transform_two_new, X_train_transform_three_new))\n",
    "    X_test_transform = sp.sparse.hstack((X_test_transform_one, X_test_transform_two_new, X_test_transform_three_new))\n",
    "    \n",
    "    fit_model = model.fit(X_train_transform, y_train)\n",
    "    train_acc = model.score(X_train_transform, y_train)\n",
    "    test_acc = model.score(X_test_transform, y_test)\n",
    "    \n",
    "    print(\"Round {}\".format(i))\n",
    "    print(\"Training Accuracy\")\n",
    "    print(train_acc)\n",
    "    print(\"Testing Accuracy\")\n",
    "    print(test_acc)\n",
    "    \n",
    "    train_accuracies.append(train_acc)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    i = i + 1\n",
    "    \n",
    "\n",
    "Y_pred = fit_model.predict(X_test_transform)\n",
    "f1_svc = f1_score(y_test, Y_pred, average = \"micro\")\n",
    "avg_train_acc_svc = sum(train_accuracies)/len(train_accuracies)\n",
    "avg_test_acc_svc = sum(test_accuracies)/len(test_accuracies)\n",
    "print(\"===========================\")\n",
    "print(\"Average Training Accuracy:\")\n",
    "print(avg_train_acc_svc)\n",
    "print(\"Average Testing Accuracy:\")\n",
    "print(avg_test_acc_svc)\n",
    "print(\"F1 Score:\")\n",
    "print(f1_svc)\n",
    "print(\"===========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4137e344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We will plot the graph to show the comparision between the accuracies for different models\n",
    "\n",
    "all_avg_train_acc = [avg_train_acc_dt*100, avg_train_acc_mnb*100, avg_train_acc_rf*100, avg_train_acc_svc*100]\n",
    "all_avg_test_acc = [avg_test_acc_dt*100, avg_test_acc_mnb*100, avg_test_acc_rf*100, avg_test_acc_svc*100]\n",
    "x_axis = [\"DT\", \"MNB\", \"RF\", \"SVC\"]\n",
    "x = np.arange(4)\n",
    "width = 0.2\n",
    "figure, axis = plt.subplots()\n",
    "rect_a = axis.bar(x - width/2, all_avg_train_acc, width, label = \"Training Accuracies\", color = \"r\")\n",
    "rect_b = axis.bar(x + width/2, all_avg_test_acc, width, label = \"Testing Accuracies\", color = \"yellow\")\n",
    "axis.set_ylabel(\"Accuracies\")\n",
    "axis.set_title(\"Accuracies for different Models using Count Vectorizer\")\n",
    "axis.set_xticks(x)\n",
    "axis.set_xticklabels(x_axis)\n",
    "axis.set_xlabel(\"Models\")\n",
    "axis.legend(loc = \"upper right\", bbox_to_anchor=(0.55, 1))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
